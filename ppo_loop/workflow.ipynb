{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb66cc9-939c-4c63-9877-a1d96065c669",
   "metadata": {},
   "source": [
    "# Connect the entire loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17236d56-82c3-4e1f-bb83-45108f81ff43",
   "metadata": {},
   "source": [
    "## Load Data Generator and PDPTW Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "22d13e60-27d1-4158-8607-19de0bb84a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jiangwolin/Desktop/Research/llm-rl/rl4co git\n"
     ]
    }
   ],
   "source": [
    "#cd rl4co\\ git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7388cc61-a4a6-49a6-9959-b62d25bafd8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# cwd => '/Users/jiangwolin/Desktop/Research/llm-rl/rl4co git'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "from inner_loop.rl4co.models.zoo import AttentionModelPolicy, AttentionModel\n",
    "from inner_loop.rl4co.envs.routing import SFGenerator, PDPTWEnv, PDPTWModEnv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "99ed879c-58ec-4c76-98a1-670af72e4509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action_mask: Tensor(shape=torch.Size([2, 61]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        capacity: Tensor(shape=torch.Size([2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        current_node: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        current_time: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        demand: Tensor(shape=torch.Size([2, 61]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        flexibility: Tensor(shape=torch.Size([2, 61]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        h3_indices: Tensor(shape=torch.Size([2, 61]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        i: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        locs: Tensor(shape=torch.Size([2, 61, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        pending_count: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        pending_schedule: Tensor(shape=torch.Size([2, 8]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        previous_action: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        time_windows: Tensor(shape=torch.Size([2, 61, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        travel_time_matrix: Tensor(shape=torch.Size([2, 207, 207]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        used_capacity: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        user_id: Tensor(shape=torch.Size([2, 61]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        vehicle_capacity: Tensor(shape=torch.Size([2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
       "        visited: Tensor(shape=torch.Size([2, 61]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([2]),\n",
       "    device=cpu,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "env = PDPTWModEnv(generator_params={\"num_customers\":30}).reset(batch_size=[2]).to(device)\n",
    "env # Contains user_id and flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15daa542-21f0-416d-a3f4-2d58f5ea30d6",
   "metadata": {},
   "source": [
    "## Load Ckpt to substitute oracle solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2a52782a-a0fc-41f7-a007-10a12d9564a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'env' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['env'])`.\n",
      "/opt/anaconda3/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'policy' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['policy'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['baseline.baseline.policy.encoder.init_embedding.project.weight', 'baseline.baseline.policy.encoder.init_embedding.project.bias', 'baseline.baseline.policy.encoder.net.layers.0.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.0.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.0.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.0.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.running_mean', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.running_var', 'baseline.baseline.policy.encoder.net.layers.0.1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.net.layers.0.2.module.lins.0.weight', 'baseline.baseline.policy.encoder.net.layers.0.2.module.lins.0.bias', 'baseline.baseline.policy.encoder.net.layers.0.2.module.lins.1.weight', 'baseline.baseline.policy.encoder.net.layers.0.2.module.lins.1.bias', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.running_mean', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.running_var', 'baseline.baseline.policy.encoder.net.layers.0.3.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.net.layers.1.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.1.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.1.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.1.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.running_mean', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.running_var', 'baseline.baseline.policy.encoder.net.layers.1.1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.net.layers.1.2.module.lins.0.weight', 'baseline.baseline.policy.encoder.net.layers.1.2.module.lins.0.bias', 'baseline.baseline.policy.encoder.net.layers.1.2.module.lins.1.weight', 'baseline.baseline.policy.encoder.net.layers.1.2.module.lins.1.bias', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.running_mean', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.running_var', 'baseline.baseline.policy.encoder.net.layers.1.3.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.net.layers.2.0.module.Wqkv.weight', 'baseline.baseline.policy.encoder.net.layers.2.0.module.Wqkv.bias', 'baseline.baseline.policy.encoder.net.layers.2.0.module.out_proj.weight', 'baseline.baseline.policy.encoder.net.layers.2.0.module.out_proj.bias', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.running_mean', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.running_var', 'baseline.baseline.policy.encoder.net.layers.2.1.normalizer.num_batches_tracked', 'baseline.baseline.policy.encoder.net.layers.2.2.module.lins.0.weight', 'baseline.baseline.policy.encoder.net.layers.2.2.module.lins.0.bias', 'baseline.baseline.policy.encoder.net.layers.2.2.module.lins.1.weight', 'baseline.baseline.policy.encoder.net.layers.2.2.module.lins.1.bias', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.weight', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.bias', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.running_mean', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.running_var', 'baseline.baseline.policy.encoder.net.layers.2.3.normalizer.num_batches_tracked', 'baseline.baseline.policy.decoder.context_embedding.project_context.weight', 'baseline.baseline.policy.decoder.pointer.project_out.weight', 'baseline.baseline.policy.decoder.project_node_embeddings.weight', 'baseline.baseline.policy.decoder.project_fixed_context.weight'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = PDPTWModEnv()\n",
    "ckpt_path = os.getcwd() + \"/inner_loop/examples/checkpoints/sf_newenv_2/epoch_epoch=067.ckpt\"\n",
    "\n",
    "torch.serialization.add_safe_globals([PDPTWModEnv])\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "state = ckpt[\"state_dict\"]\n",
    "\n",
    "model = AttentionModel(env=PDPTWEnv())\n",
    "model.load_state_dict(state, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "163b39bc-4c3f-4297-93fe-9e8813e62b99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': tensor([-689.9833]),\n",
       " 'log_likelihood': tensor([-31.8689], grad_fn=<SumBackward1>),\n",
       " 'actions': tensor([[49, 19, 13, 20, 47, 59, 35, 15, 25, 48,  1,  2,  0, 11, 43, 12, 16, 60,\n",
       "           0, 44, 14, 36, 53, 55, 26, 54, 56,  0, 50, 27, 37, 38, 28, 41,  3, 45,\n",
       "          42, 57,  5, 21, 46,  7,  6, 22,  8,  9, 10,  0, 39, 40,  4, 33, 29, 34,\n",
       "          31, 23, 32, 30, 17, 18,  0, 58, 51, 24, 52,  0]])}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "td_init = PDPTWModEnv(generator_params={\"num_customers\":30}).reset(batch_size=[1]).to(device)\n",
    "trained_policy = model.policy.to(device)\n",
    "out = trained_policy(td_init.clone(), phase='test', decode_type=\"sampling\", return_actions=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aac1ab-561f-40fd-9a3c-7876102b1d11",
   "metadata": {},
   "source": [
    "## Connect Data Generator to PPO Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0107983-ded8-43c4-9305-249e515d74b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1b61ec7c-1318-4694-b2e9-16fe4ab50b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PDPTWModEnv()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing random policy\n",
    "env = PDPTWModEnv()\n",
    "\n",
    "# Policy: neural network, in this case with encoder-decoder architecture\n",
    "policy = AttentionModelPolicy(env_name=env.name, \n",
    "                              embed_dim=128,\n",
    "                              num_encoder_layers=3,\n",
    "                              num_heads=8,\n",
    "                            )\n",
    "td = env.reset(batch_size=[1]) \n",
    "out = policy(td_init.clone(), phase=\"test\", decode_type=\"greedy\", return_actions=True)\n",
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf31f91-0fd4-472c-8549-eed50e460bba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
