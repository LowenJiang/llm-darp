{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4f207ea-bbee-41c0-b2d0-efcf9269676a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'ABCMeta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CVRPTWEnv, DARPEnv, PDPTWEnv\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrouting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CVRPTWGenerator, DARPGenerator, PDPTWGenerator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m REINFORCE\n",
      "File \u001b[0;32m~/Desktop/LLMOR/Scripts/llm-darp/rl4co/envs/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Base environment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RL4COEnvBase\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# EDA\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DPPEnv, MDPPEnv\n",
      "File \u001b[0;32m~/Desktop/LLMOR/Scripts/llm-darp/rl4co/envs/common/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RL4COEnvBase\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator, get_sampler\n",
      "File \u001b[0;32m~/Desktop/LLMOR/Scripts/llm-darp/rl4co/envs/common/base.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensordict\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensordict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDict\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EnvBase\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TensorDictDataset\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_npz_to_tensordict\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrl4co\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_num_starts, select_start_nodes\n",
      "File \u001b[0;32m~/Desktop/LLMOR/Scripts/llm-darp/rl4co/data/dataset.py:15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     td_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFastTdDataset\u001b[39;00m(Dataset):\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Note:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        Check out the issue on tensordict for more details:\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m        https://github.com/pytorch-labs/tensordict/issues/374.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, td: TensorDict):\n",
      "File \u001b[0;32m~/Desktop/LLMOR/Scripts/llm-darp/rl4co/data/dataset.py:36\u001b[0m, in \u001b[0;36mFastTdDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_key\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ExtraKeyDataset(\u001b[38;5;28mself\u001b[39m, value, key_name\u001b[38;5;241m=\u001b[39mkey)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(batch: \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTensorDict\u001b[49m):\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Collate function compatible with TensorDicts that reassembles a list of dicts.\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'ABCMeta'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from rl4co.envs import CVRPTWEnv, DARPEnv, PDPTWEnv\n",
    "from rl4co.envs.routing import CVRPTWGenerator, DARPGenerator, PDPTWGenerator\n",
    "from rl4co.models import REINFORCE\n",
    "from rl4co.utils.trainer import RL4COTrainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, RichModelSummary\n",
    "from rl4co.utils.decoding import rollout, random_policy\n",
    "from rl4co.envs.common import RL4COEnvBase, Generator, get_sampler\n",
    "from rl4co.models.zoo import AttentionModel, AttentionModelPolicy\n",
    "from rl4co.utils.ops import gather_by_index, get_tour_length\n",
    "\n",
    "from ortools_solver import solve_darp_with_ortools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0aafa",
   "metadata": {},
   "source": [
    "# generate PDPTW instances via PDPTWGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8814fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_init = PDPTWEnv(generator_params={\"num_loc\":30}).reset(batch_size=[1]).to(device)\n",
    "td_init\n",
    "print(solve_darp_with_ortools(td_init, vehicle_speed=5.0, time_limit_seconds=150, max_pdptw_vehicles=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(td_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_init = PDPTWGenerator(num_loc=10)._generate(batch_size=[4])\n",
    "print(\"FIELDS:\", end=' ')\n",
    "for key in list(td_init.keys()):\n",
    "    print(key, end=', ')\n",
    "\n",
    "for key in list(td_init.keys()):\n",
    "    print(f\"{key} size:  {td_init[key].shape}\" )\n",
    "\n",
    "for key in list(td_init.keys()):\n",
    "    print(f\"{key} content:  {td_init[0][key]}\" )\n",
    "\n",
    "# Vehicle_speed = 5\n",
    "\n",
    "import torch\n",
    "from examples.ortools_solver import solve_darp_with_ortools\n",
    "\n",
    "td = td_init\n",
    "print(solve_darp_with_ortools(td, vehicle_speed=5.0, time_limit_seconds=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82a066-dd32-4df7-81bf-2f9b0fd31b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "policy_new = model_ckpt.policy.to(device)\n",
    "#env = new_model_checkpoint.env.to(device)\n",
    "env = DARPEnv(generator_params={'num_loc': 30, \"num_agents\":6}) \n",
    "\n",
    "td_init = env.reset(batch_size=[1]).to(device)\n",
    "out = policy_new(td_init.clone(), env, phase=\"test\", decode_type=\"greedy\")\n",
    "\n",
    "print(f\"Tour lengths: {[f'{-r.item():.2f}' for r in out['reward']]}\")\n",
    "for td, actions in zip(td_init, out['actions'].cpu()):\n",
    "    env.render(td, actions)\n",
    "print(out)\n",
    "print(td_init['time_windows'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e125f-0586-4a25-8225-4c4decb33fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_init[\"locs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459c31f-6c1b-4693-896b-be93bba1df4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = DARPEnv(generator_params={'num_loc': 10, \"num_agents\":6}) \n",
    "\n",
    "td_init = env.reset(batch_size=[1]).to(device)\n",
    "\n",
    "or_out = solve_darp_with_ortools(td_init, time_limit_seconds=5)\n",
    "\n",
    "for td, actions in zip(td_init, or_out['actions'].cpu()):\n",
    "    env.render(td, actions)\n",
    "print(or_out)\n",
    "print(td_init['time_windows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f60ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e270e-5592-4687-8f65-2e1fc6c29771",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = policy_new(td_init.clone(), env, phase=\"test\", decode_type=\"greedy\")\n",
    "\n",
    "for td, actions in zip(td_init, out['actions'].cpu()):\n",
    "    env.render(td, actions)\n",
    "print(out)\n",
    "print(td_init['time_windows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd39c03f-4ee5-4525-844f-6648c0c4f0a4",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836f767b-3578-455c-a319-c6423a5cdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "# your pieces: assumed to exist\n",
    "# from your_module import DARPEnv, solve_darp_with_ortools, policy_new\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_loc_list = [10, 14, 18, 22, 26, 30]   # 6 columns\n",
    "num_agents_list = [6]            # 4 rows\n",
    "n_eval = 5                                # increase for smoother numbers\n",
    "\n",
    "# To store results\n",
    "pct_table = []\n",
    "\n",
    "for na in num_agents_list:\n",
    "    row_vals = []\n",
    "    for nl in tqdm(num_loc_list):\n",
    "        # collect rewards over episodes\n",
    "        or_rewards = []\n",
    "        pol_rewards = []\n",
    "\n",
    "        # build env for this setting\n",
    "        # (if your DARPEnv signature is different, adjust here)\n",
    "        env = DARPEnv(generator_params={\n",
    "            \"num_loc\": nl,\n",
    "            \"num_agents\": na,\n",
    "        })\n",
    "\n",
    "        for _ in range(n_eval):\n",
    "            # reset once and send to device\n",
    "            td_init = env.reset(batch_size=[1]).to(device)\n",
    "\n",
    "            # OR-Tools solve\n",
    "            or_out = solve_darp_with_ortools(td_init, time_limit_seconds=10)\n",
    "            # or_out['reward'] is a tensor([-452.5]) per your example\n",
    "            or_reward = or_out[\"reward\"].detach().cpu().item()\n",
    "\n",
    "            # Policy run on the *same* initial state\n",
    "            pol_out = policy_new(td_init.clone(), env, phase=\"test\", decode_type=\"greedy\")\n",
    "            pol_reward = pol_out[\"reward\"].detach().cpu().item()\n",
    "\n",
    "            or_rewards.append(or_reward)\n",
    "            pol_rewards.append(pol_reward)\n",
    "\n",
    "        # average\n",
    "        avg_or = sum(or_rewards) / len(or_rewards)\n",
    "        avg_pol = sum(pol_rewards) / len(pol_rewards)\n",
    "\n",
    "        # guard against 0 (shouldn't happen often, but just in case)\n",
    "        if abs(avg_or) < 1e-6:\n",
    "            pct_diff = 0.0\n",
    "        else:\n",
    "            pct_diff = 100.0 * (avg_pol - avg_or) / abs(avg_or)\n",
    "\n",
    "        row_vals.append(pct_diff)\n",
    "    pct_table.append(row_vals)\n",
    "\n",
    "# make DataFrame: rows = num_agents, cols = num_loc\n",
    "df = pd.DataFrame(\n",
    "    pct_table,\n",
    "    index=[f\"agents={na}\" for na in num_agents_list],\n",
    "    columns=[f\"loc={nl}\" for nl in num_loc_list],\n",
    ")\n",
    "\n",
    "print(df)\n",
    "\n",
    "# seaborn-style 4x6 heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.heatmap(\n",
    "    df,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    cbar_kws={\"label\": \"% diff (policy vs OR-Tools)\"}\n",
    ")\n",
    "ax.set_title(\"Policy vs OR-Tools: % Cost Difference\\n\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1449ae7-06bc-4b34-9ae6-c0c57ce83478",
   "metadata": {},
   "outputs": [],
   "source": [
    "or_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65b10a-d860-4df9-bb0f-98dcb65f0951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
